---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    prometheus: app-sre
    role: alert-rules
  name: rhobs-slos-rhobsp02ue1-prod
spec:
  groups:
  - interval: 2m30s
    name: api-metrics-write-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        severity: high
        slo: api-metrics-write-availability-slo
  - interval: 30s
    name: api-metrics-write-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-write-availability-slo
  - interval: 30s
    name: api-metrics-write-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-query-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        severity: high
        slo: api-metrics-query-availability-slo
  - interval: 30s
    name: api-metrics-query-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-query-availability-slo
  - interval: 30s
    name: api-metrics-query-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-query-range-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        severity: high
        slo: api-metrics-query-range-availability-slo
  - interval: 30s
    name: api-metrics-query-range-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-query-range-availability-slo
  - interval: 30s
    name: api-metrics-query-range-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-raw-write-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4w]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        severity: high
        slo: api-rules-raw-write-availability-slo
  - interval: 30s
    name: api-rules-raw-write-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[5m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[30m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[2h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[6h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        service: observatorium-api
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        method: PUT
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        method: PUT
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        method: PUT
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        method: PUT
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-rules-raw-write-availability-slo
  - interval: 30s
    name: api-rules-raw-write-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}
        or vector(0))
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-raw-read-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4w]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        severity: high
        slo: api-rules-raw-read-availability-slo
  - interval: 30s
    name: api-rules-raw-read-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        method: GET
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        method: GET
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        method: GET
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        method: GET
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-rules-raw-read-availability-slo
  - interval: 30s
    name: api-rules-raw-read-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0))
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-read-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4w]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        severity: high
        slo: api-rules-read-availability-slo
  - interval: 30s
    name: api-rules-read-availability-slo
    rules:
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate5m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate30m
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate1h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate2h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate6h
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate1d
    - expr: sum(rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
        / sum(rate(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        service: observatorium-api
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (14 * (1-0.95)) and http_requests:burnrate1h{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        method: GET
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (7 * (1-0.95)) and http_requests:burnrate6h{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        method: GET
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (2 * (1-0.95)) and http_requests:burnrate1d{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        method: GET
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (1 * (1-0.95)) and http_requests:burnrate4d{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        method: GET
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-rules-read-availability-slo
  - interval: 30s
    name: api-rules-read-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0)) / sum(http_requests:increase4w{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0))
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-sync-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[4w]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: absent(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        slo: api-rules-sync-availability-slo
  - interval: 30s
    name: api-rules-sync-availability-slo
    rules:
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[5m]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[5m]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate5m
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[30m]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[30m]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate30m
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[1h]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[1h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate1h
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[2h]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[2h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate2h
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[6h]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[6h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate6h
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[1d]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[1d]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate1d
    - expr: sum(rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[4d]))
        / sum(rate(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"}[4d]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate4d
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate5m{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (14 * (1-0.95)) and client_api_requests:burnrate1h{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate30m{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (7 * (1-0.95)) and client_api_requests:burnrate6h{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate2h{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (2 * (1-0.95)) and client_api_requests:burnrate1d{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate6h{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (1 * (1-0.95)) and client_api_requests:burnrate4d{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production",slo="api-rules-sync-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-rules-sync-availability-slo
  - interval: 30s
    name: api-rules-sync-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_window
    - expr: 1 - sum(client_api_requests:increase4w{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}
        or vector(0)) / sum(client_api_requests:increase4w{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"})
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_availability
    - expr: sum(client_api_requests_total{client="reload",container="thanos-rule-syncer",namespace="observatorium-mst-production"})
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_requests_total
    - expr: sum(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-production"}
        or vector(0))
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-alerting-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[4w]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: absent(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        slo: api-alerting-availability-slo
  - interval: 30s
    name: api-alerting-availability-slo
    rules:
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[5m]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[5m]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate5m
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[30m]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[30m]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate30m
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[1h]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[1h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate1h
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[2h]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[2h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate2h
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[6h]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[6h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate6h
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[1d]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[1d]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate1d
    - expr: sum(rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}[4d]))
        / sum(rate(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"}[4d]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-production
        service: observatorium-api
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate4d
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate5m{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (14 * (1-0.95)) and thanos_alert_sender_alerts_dropped:burnrate1h{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate30m{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (7 * (1-0.95)) and thanos_alert_sender_alerts_dropped:burnrate6h{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate2h{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (2 * (1-0.95)) and thanos_alert_sender_alerts_dropped:burnrate1d{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate6h{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (1 * (1-0.95)) and thanos_alert_sender_alerts_dropped:burnrate4d{container="thanos-rule",namespace="observatorium-mst-production",slo="api-alerting-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-alerting-availability-slo
  - interval: 30s
    name: api-alerting-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_window
    - expr: 1 - sum(thanos_alert_sender_alerts_dropped:increase4w{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}
        or vector(0)) / sum(thanos_alert_sender_alerts_dropped:increase4w{container="thanos-rule",namespace="observatorium-mst-production"})
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_availability
    - expr: sum(thanos_alert_sender_alerts_dropped_total{container="thanos-rule",namespace="observatorium-mst-production"})
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_requests_total
    - expr: sum(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-production"}
        or vector(0))
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-alerting-notif-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[4w]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: absent(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        slo: api-alerting-notif-availability-slo
  - interval: 30s
    name: api-alerting-notif-availability-slo
    rules:
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[5m]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[5m]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate5m
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[30m]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[30m]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate30m
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[1h]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[1h]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate1h
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[2h]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[2h]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate2h
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[6h]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[6h]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate6h
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[1d]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[1d]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate1d
    - expr: sum(rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}[4d]))
        / sum(rate(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"}[4d]))
      labels:
        namespace: observatorium-mst-production
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate4d
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate5m{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (14 * (1-0.95)) and alertmanager_notifications_failed:burnrate1h{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (14 * (1-0.95))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate30m{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (7 * (1-0.95)) and alertmanager_notifications_failed:burnrate6h{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (7 * (1-0.95))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate2h{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (2 * (1-0.95)) and alertmanager_notifications_failed:burnrate1d{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (2 * (1-0.95))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate6h{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (1 * (1-0.95)) and alertmanager_notifications_failed:burnrate4d{namespace="observatorium-mst-production",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (1 * (1-0.95))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-alerting-notif-availability-slo
  - interval: 30s
    name: api-alerting-notif-availability-slo-generic
    rules:
    - expr: "0.95"
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_window
    - expr: 1 - sum(alertmanager_notifications_failed:increase4w{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}
        or vector(0)) / sum(alertmanager_notifications_failed:increase4w{namespace="observatorium-mst-production",service="observatorium-alertmanager"})
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_availability
    - expr: sum(alertmanager_notifications_failed_total{namespace="observatorium-mst-production",service="observatorium-alertmanager"})
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_requests_total
    - expr: sum(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-production",service="observatorium-alertmanager"}
        or vector(0))
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-write-latency-slo-increase
    rules:
    - expr: sum by(code) (increase(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:increase4w
    - expr: sum by(code) (increase(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        le: "5"
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: absent(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        severity: high
        slo: api-metrics-write-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: absent(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        severity: high
        slo: api-metrics-write-latency-slo
  - interval: 30s
    name: api-metrics-write-latency-slo
    rules:
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[5m])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate5m
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[30m])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate30m
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[1h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate1h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[2h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate2h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[6h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate6h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[1d])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate1d
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[4d])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        service: observatorium-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate4d
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate5m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (14 * (1-0.9)) and http_request_duration_seconds:burnrate1h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1h
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate30m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (7 * (1-0.9)) and http_request_duration_seconds:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 6h
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate2h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (2 * (1-0.9)) and http_request_duration_seconds:burnrate1d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 1d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (1 * (1-0.9)) and http_request_duration_seconds:burnrate4d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long_burnrate_window: 4d
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-write-latency-slo
  - interval: 30s
    name: api-metrics-write-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_window
    - expr: sum(http_request_duration_seconds:increase4w{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5",slo="api-metrics-write-latency-slo"}
        or vector(0)) / sum(http_request_duration_seconds:increase4w{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="",slo="api-metrics-write-latency-slo"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_availability
    - expr: sum(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_requests_total
    - expr: sum(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        - sum(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-1M-latency-slo-increase
    rules:
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4w]))
      labels:
        le: "10"
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-1M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-1M-latency-slo
  - interval: 30s
    name: api-metrics-read-1M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-read-1M-latency-slo
  - interval: 30s
    name: api-metrics-read-1M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="",namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="10",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-10M-latency-slo-increase
    rules:
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[4w]))
      labels:
        le: "30"
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-10M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-10M-latency-slo
  - interval: 30s
    name: api-metrics-read-10M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        query: query-path-sli-10M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-read-10M-latency-slo
  - interval: 30s
    name: api-metrics-read-10M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="",namespace="observatorium-mst-production",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="30",namespace="observatorium-mst-production",query="query-path-sli-10M-samples"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-100M-latency-slo-increase
    rules:
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(http_code) (increase(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4w]))
      labels:
        le: "120"
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-100M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        slo: api-metrics-read-100M-latency-slo
  - interval: 30s
    name: api-metrics-read-100M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long_burnrate_window: 1h
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 5m
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long_burnrate_window: 6h
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: high
        short_burnrate_window: 30m
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long_burnrate_window: 1d
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 2h
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/7f4df1c2d5518d5c3f2876ca9bb874a8/rhobsp02ue1-production-slos?orgId=1&refresh=10s&var-datasource=rhobsp02ue1-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long_burnrate_window: 4d
        namespace: observatorium-mst-production
        query: query-path-sli-1M-samples
        service: observatorium-api
        severity: warning
        short_burnrate_window: 6h
        slo: api-metrics-read-100M-latency-slo
  - interval: 30s
    name: api-metrics-read-100M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{http_code=~"^2..$",le="",namespace="observatorium-mst-production",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{http_code=~"^2..$",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{http_code=~"^2..$",le="120",namespace="observatorium-mst-production",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_errors_total
